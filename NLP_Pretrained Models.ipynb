{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcea17a-08b3-48eb-bd03-369f1fc736ba",
   "metadata": {},
   "source": [
    "### Using Pretrained Models to Classify Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9bf3cc-ff9e-4a84-bc7c-61c057aa0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 7.1/12.0 MB 40.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 29.9 MB/s  0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 19.0 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 27.7 MB/s  0:00:00\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [regex]\n",
      "   ----- ---------------------------------- 1/7 [regex]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------------- ---------------------- 3/7 [filelock]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------------- 7/7 [transformers]\n",
      "\n",
      "Successfully installed filelock-3.20.1 fsspec-2025.12.0 huggingface-hub-0.36.0 regex-2025.11.3 safetensors-0.7.0 tokenizers-0.22.1 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installs the 'transformers' library from Hugging Face\n",
    "# This library allows working with pre-trained natural language processing (NLP) models\n",
    "# such as BERT, GPT, RoBERTa, etc.\n",
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3547b0-442b-4be8-bfce-11e5ae6b6ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\surface\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installs the 'torch' library (PyTorch)\n",
    "# PyTorch is a popular deep learning framework used for building and training\n",
    "# neural networks, handling tensors, and performing GPU-accelerated computations.\n",
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4edb7421-361f-4e58-9e82-d45b37ffcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the 'pipeline' function from the Hugging Face transformers library\n",
    "# The pipeline function provides an easy way to use pre-trained NLP models\n",
    "# for tasks like text classification, question answering, text generation, etc.\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f95b7f-4291-44c2-9d1c-779179d8465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Creates a sentiment analysis pipeline using Hugging Face transformers\n",
    "# \"sentiment-analysis\" specifies the NLP task\n",
    "# 'distilbert/distilbert-base-uncased-finetuned-sst-2-english' is the pre-trained model fine-tuned for sentiment analysis\n",
    "# 'revision=\"714eb0f\"' specifies the exact version of the model to use\n",
    "# The resulting 'model' object can be used to analyze the sentiment of text (positive/negative)\n",
    "model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    revision=\"714eb0f\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10701754-9003-417a-8d1e-cf913393ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995430707931519}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uses the previously created sentiment analysis pipeline to analyze the sentiment of the given text\n",
    "# The text: \"The long lines and poor customer service really turned me off\" expresses a negative experience\n",
    "# The output will typically be a dictionary with 'label' (e.g., POSITIVE or NEGATIVE) and 'score' (confidence level)\n",
    "model('The long lines and poor customer service really turned me off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561f1a52-82b0-4a44-91ee-2becf48dd9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16da2a99e76a4b7cbf405ea0f92f746d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/851 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408414e5fbe04dc4a453dfdce610b216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdcc082a37d49df844a513da978cf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b997df0b58d6437e87badce24bd5c519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0d9c3642754edf80660d43fd987247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8427aae86a474c41a2eb2dafb43d0e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Very Positive', 'score': 0.5586305260658264}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the classification pipeline with the specified model\n",
    "pipe = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8b9c11-ed2d-4878-8362-159b3cd603ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Very Positive', 'score': 0.5586305260658264}]\n"
     ]
    }
   ],
   "source": [
    "# Classify a new sentence\n",
    "sentence = \"I love this product! It's amazing and works perfectly.\"\n",
    "result = pipe(sentence)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fdde67-14d4-4a02-81f2-50306cfe29fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Negative', 'score': 0.9187023639678955}]\n"
     ]
    }
   ],
   "source": [
    "# Classify a new sentence\n",
    "sentence = \"I  didn't love this product! It's not  amazing and doesn't work perfectly.\"\n",
    "result = pipe(sentence)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b155c-6955-4803-b412-36645b998df0",
   "metadata": {},
   "source": [
    "Itâ€™s just as easy to analyze a text string for emotion by loading a different pretrained\n",
    "model. To demonstrate, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99d64bd3-8b1c-4356-aae2-815e49c34b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae758dee10a4bb1987a0045704a3029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad3535f7a4c44a2b79a4769eaa83a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb08a4d07bc4d4f9e8712d3df1b3cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37952b03707f4e3881931ace507248c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4bdb01c2634a6eacf3660b14ed8a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\SURFACE\\anaconda3\\envs\\testingopenai\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creates a text classification pipeline using Hugging Face transformers\n",
    "# 'text-classification' specifies the NLP task of classifying text into categories\n",
    "# 'bhadresh-savani/distilbert-base-uncased-emotion' is a pre-trained model fine-tuned for emotion detection\n",
    "# 'return_all_scores=True' ensures the pipeline returns the scores for all possible emotions, not just the top one\n",
    "# The resulting 'model' object can be used to analyze emotions in text (e.g., joy, sadness, anger, fear, etc.)\n",
    "model = pipeline(\n",
    "    'text-classification',\n",
    "    model='bhadresh-savani/distilbert-base-uncased-emotion',\n",
    "    return_all_scores=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d35bad-65e5-4b64-86af-659969bdaf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'sadness', 'score': 0.10836926847696304},\n",
       "  {'label': 'joy', 'score': 0.0023739372845739126},\n",
       "  {'label': 'love', 'score': 0.0006029442301951349},\n",
       "  {'label': 'anger', 'score': 0.8861261606216431},\n",
       "  {'label': 'fear', 'score': 0.0019340685103088617},\n",
       "  {'label': 'surprise', 'score': 0.0005936266970820725}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model('The long lines and poor customer service really turned me off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f80ba-ce8f-4ba3-8145-73560487f68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:testingopenai]",
   "language": "python",
   "name": "conda-env-testingopenai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
